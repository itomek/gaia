---
title: "Quickstart"
description: "Build your first AI agent in 5 minutes"
---

<Info>
  **First time here?** Complete the [Setup](/setup) guide first to install GAIA and its dependencies.
</Info>

## Build Your First Agent

<Warning>
  Make sure your virtual environment is still activated (you should see `(.venv)` in your prompt). If commands aren't working as expected, try prefixing them with [`uv run`](https://docs.astral.sh/uv/reference/cli/#uv-run).
</Warning>

Using your text editor, create a file named `my_agent.py` in your project directory:

```python
import platform
from datetime import datetime
from gaia.agents.base.agent import Agent
from gaia.agents.base.tools import tool

class MyAgent(Agent):
    """A simple agent that can report system information."""

    def _get_system_prompt(self) -> str:
        return """You are a system monitoring assistant.
When users ask about time or system details, use the get_system_info tool."""

    def _register_tools(self):
        @tool
        def get_system_info() -> dict:
            """Get current time, date, platform, and Python version."""
            return {
                "time": datetime.now().strftime("%H:%M:%S"),
                "date": datetime.now().strftime("%Y-%m-%d"),
                "platform": platform.system(),
                "python": platform.python_version()
            }

# Use the agent
agent = MyAgent()
result = agent.process_query("What time is it and what system am I on?")
print(result.get("result"))
```

**Run it** (in your terminal/PowerShell):
```
python my_agent.py
```

<Note>
  First run may take a moment while GAIA starts Lemonade Server and loads the LLM.
</Note>

You'll see the agent thinking, creating a plan, and executing the tool:

```
ðŸ¤– Processing: 'What time is it and what system am I on?'
...
ðŸ”§ Executing operation
  Tool: get_system_info

âœ… Tool execution complete
{
  "time": "15:03:26",
  "date": "2025-12-17",
  "platform": "Windows",
  "python": "3.12.12"
}
...
âœ¨ Processing complete!
```

Final output (will vary based on your system):
```
The current time is 15:03:26 and you are on a Windows system running Python 3.12.12.
```

<Success>
  **It works!** The agent called the `get_system_info` tool and returned real data from your system.
</Success>

<Info>
  **Tip:** The tool's docstring is how the LLM knows what the tool does. Be descriptive!
  `"""Get current time, date, platform, and Python version."""` tells the LLM this tool can answer time-related questions.
</Info>

---

## How It Works

### The Agent Base Class

The `Agent` class handles the core loop: receiving queries, calling the LLM, executing tools, and returning responses. You extend it by defining:

- **`_get_system_prompt()`** â€” Instructions that shape the agent's behavior
- **`_register_tools()`** â€” Functions the agent can call to take actions

### System Prompt

The system prompt tells your agent who it is and how to make decisions. You define it by returning a string:

```python
def _get_system_prompt(self) -> str:
    return """You are a system monitoring assistant.
When users ask about time or system details, use the get_system_info tool."""
```

For agents, a good prompt includes:
- **Role**: What the agent specializes in â€” *"You are a code review assistant..."*
- **Tool guidance**: When to use tools vs. respond directly â€” *"Use the search tool for questions about files..."*
- **Style**: Tone and boundaries â€” *"Be concise. Only answer questions about this codebase."*

The system prompt and tools work together: the prompt shapes *how* the agent reasons, while tools define *what* it can do.

### Tools

Tools are just Python functions with the `@tool` decorator:

```python
@tool
def get_system_info() -> dict:
    """Get current time, date, platform, and Python version."""
    return {"time": "14:32:05", "platform": "Windows", ...}
```

The LLM automatically sees all registered tools and their docstrings. When you ask a question, it decides which tools (if any) to call based on their descriptions. **That's it** â€” no configuration, no routing logic. Just write functions and the agent knows what it can do.

### The Agent Loop

When you call `agent.process_query("What time is it?")`, GAIA runs an iterative loop:

<Steps>
  <Step title="Think">
    The LLM receives your query plus the system prompt and available tools. It decides what to do next.
  </Step>

  <Step title="Act">
    If the LLM decides to use a tool, GAIA executes it and captures the result.
  </Step>

  <Step title="Observe">
    The tool result is sent back to the LLM, which can then decide to call another tool or respond.
  </Step>

  <Step title="Respond">
    When the LLM has enough information, it generates a natural language response for the user.
  </Step>
</Steps>

This loop continues until the LLM decides it has a complete answer. Complex tasks may involve multiple tool calls before responding.

---

## What's Next?

<CardGroup cols={2}>
  <Card title="Developer Guide" icon="code" href="/reference/dev">
    Testing, linting, and contributing to GAIA
  </Card>

  <Card title="Chat Agent Playbook" icon="book-open" href="/playbooks/chat-agent/part-1-getting-started">
    Step-by-step guide to building a document Q&A agent with RAG
  </Card>

  <Card title="Chat SDK" icon="message" href="/guides/chat">
    Build conversational AI with memory and document Q&A
  </Card>

  <Card title="Voice Integration" icon="microphone" href="/guides/talk">
    Add speech recognition and text-to-speech to your agent
  </Card>

  <Card title="SDK Reference" icon="book" href="/sdk">
    Complete API documentation for all GAIA components
  </Card>

  <Card title="CLI Reference" icon="terminal" href="/reference/cli">
    Command-line tools for chat, voice, RAG, and more
  </Card>
</CardGroup>

<Tip>
  **Stuck?** Join our [Discord](https://discord.com/channels/1392562559122407535/1402013282495102997) or [create an issue](https://github.com/amd/gaia/issues) on GitHub.
</Tip>

---

<small style="color: #666;">

**License**

Copyright(C) 2024-2025 Advanced Micro Devices, Inc. All rights reserved.

SPDX-License-Identifier: MIT

</small>
